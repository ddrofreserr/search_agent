<!doctype html>
<html lang='en'>
<head>
<meta charset='utf-8'/>
<meta name='viewport' content='width=device-width, initial-scale=1'/>
<title>Search Agent Report</title>
<style>body{font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Arial;max-width:920px;margin:32px auto;padding:0 16px;line-height:1.5;color:#111}.muted{color:#666}.card{border:1px solid #e6e6e6;border-radius:14px;padding:16px;margin:14px 0}h1{font-size:28px;margin:0 0 8px}h2{font-size:18px;margin:24px 0 10px}h3{font-size:15px;margin:0 0 8px}pre{white-space:pre-wrap;background:#fafafa;border:1px solid #eee;border-radius:12px;padding:12px}a{color:#0b57d0;text-decoration:none}a:hover{text-decoration:underline}ul{margin:8px 0 0 18px}</style>
</head>
<body>
<h1>Search Agent Report</h1>
<div class='card'>
<div><b>Query:</b> Find papers about rotary positional embeddings and their implementations</div>
<div><b>Source:</b> github ()</div>
<div class='muted'><b>Why:</b> hybrid: github fused=0.7318 (dense=0.1749, bm25=0.8834, alpha=0.65)</div>
</div>
<h2>Evidence</h2>
<div class='card'>
<h3>Result 1: Implementation of Rotary Embeddings, from the Roformer paper, in Pytorch</h3>
<div><b>URL:</b> <a href='https://github.com/lucidrains/rotary-embedding-torch' target='_blank' rel='noreferrer'>https://github.com/lucidrains/rotary-embedding-torch</a></div>
<div class='muted' style='margin-top:6px'>A standalone library for adding rotary embeddings to transformers in Pytorch, following its success as relative positional encoding.</div>
<div style='margin-top:10px'><b>Quotes:</b></div>
<ul>
<li>GitHub - lucidrains/rotary-embedding-torch: Implementation of Rotary Embeddings, from the Roformer paper, in Pytorch</li>
<li>Search code, repositories, users, issues, pull requests...</li>
</ul>
</div>
<div class='card'>
<h3>Result 2: VachanVY/Rotary-Embeddings: Simple Implementation of ... - GitHub</h3>
<div><b>URL:</b> <a href='https://github.com/VachanVY/Rotary-Embeddings' target='_blank' rel='noreferrer'>https://github.com/VachanVY/Rotary-Embeddings</a></div>
<div class='muted' style='margin-top:6px'>Jun 21, 2025 Â· Simple implementation of rotary positional embeddings (RoPE) and sinusoidal positional embeddings in JAX.</div>
<div style='margin-top:10px'><b>Quotes:</b></div>
<ul>
<li>GitHub - VachanVY/Rotary-Embeddings: Simple Implementation of Rotary Positional Embeddings (RoPE) and Sinusoidal Positional Embeddings in JAX</li>
<li>Search code, repositories, users, issues, pull requests...</li>
</ul>
</div>
<h2>Answer</h2>
<div class='card'>
<pre>What I found:
- GitHub - lucidrains/rotary-embedding-torch: Implementation of Rotary Embeddings, from the Roformer paper, in Pytorch. This library provides a standalone solution for adding rotary embeddings to transformers using PyTorch.
  - [GitHub - lucidrains/rotary-embedding-torch](https://github.com/lucidrains/rotary-embedding-torch)
- GitHub - VachanVY/Rotary-Embeddings: Simple Implementation of ... This repository offers a simple implementation for rotary positional embeddings (RoPE) and sinusoidal positional embeddings in JAX.

Therefore, you can find papers about rotary positional embeddings through the code implementations provided by lucidrains/rotary-embedding-torch and VachanVY/Rotary-Embeddings.</pre>
</div>
</body></html>